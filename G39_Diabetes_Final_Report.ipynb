{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db69f723-df9c-44fd-9c61-1e382a620bde",
   "metadata": {},
   "source": [
    "# Classification: Predicting Diabetes Based on Modifiable Factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d613b-5f56-4fc1-817b-958b416d3103",
   "metadata": {},
   "source": [
    "(max 2000 written words, not including citations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5052b3d8-0b32-4358-b292-1643e48123c3",
   "metadata": {},
   "source": [
    "Ensure that the following packages are installed before proceeding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e27b32-ed4c-49c9-8422-2d156ed7f589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# installation packages commented out for convenience.\n",
    "\n",
    "#install.packages(\"tidyverse\")\n",
    "#install.packages(\"tidymodels\")\n",
    "#install.packages(\"gridExtra\")\n",
    "#install.packages(\"repr\")\n",
    "#install.packages(\"kknn\")\n",
    "#install.packages(\"cowplot\")\n",
    "#install.packages(\"shiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5841a9b6-875d-4dde-8941-cbcef2c278ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set seed and load necessary packages\n",
    "\n",
    "set.seed(1000)\n",
    "\n",
    "library(\"tidyverse\")\n",
    "library(\"tidymodels\")\n",
    "library(\"gridExtra\")\n",
    "library(\"repr\")\n",
    "library(\"kknn\")\n",
    "library(\"cowplot\")\n",
    "library(\"shiny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e9f481-6ad7-414d-9339-4bf3c26b88ca",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadce434-0025-4abe-98a4-a5fe23d82c48",
   "metadata": {},
   "source": [
    "Diabetes mellitus is a serious disease causing severe health complications such as heart failure, with the main associated cause of death being coronary heart disease (Das, 2014). Our project attempts to predict the development of diabetes mellitus based on modifiable measures of health (eg. BMI), specifically in a population of adult female patients (aged 21 and above) of Pima Indian descent. Those of Indian descent often have higher rates of diabetes, suggesting a potential genetic predisposition to insulin resistance, however many other factors can play a role in the pathogenesis of diabetes. There are many known risk factors associated with this disorder, some of which include parental diabetes, obesity, and genetic components (Das, 2014). High prevalence of diabetes mellitus is not only a severe health issue, but also places a significant strain on the healthcare system (Krishnamoorthy et al., 2022).\n",
    "\n",
    "In order to predict the development of diabetes mellitus, we aim to train a K-nearest neighbors classifier on a dataset of Pima Indian female patients that were monitored longitudinally for the onset of diabetes. This `Diabetes Dataset` was uploaded to Kaggle by user Mehmet Akturk and sourced from the National Institute of Diabetes and Digestive and Kidney Diseases (Smith et al., 1988). The study population consisted of adult female patients (at least 21 years of age) of Pima Indian heritage (n = 768), living near Phoenix, Arizona (USA). Researchers collected the following data:\n",
    " 1. `Pregnancies`: Number of times pregnant\n",
    " 2. `Glucose`: Plasma glucose concentration level at 2 hours in an oral glucose tolerance test (ie. glucose test, mg/dl)\n",
    " 3. `BloodPressure`: Diastolic blood pressure (mmHg)\n",
    " 4. `SkinThickness`: Triceps skin fold thickness (mm) (measure of body fat)\n",
    " 5. `Insulin`: 2-Hour serum insulin (µU/mL)\n",
    " 6. `BMI`: Body mass index (kg/m^2)\n",
    " 7. `DiabetesPedigreeFunction`: Diabetes pedigree function (probability of diabetes based on family history) \n",
    " 8. `Age`: Age (years)\n",
    " 9. `Outcome`: 0 = glucose test negative for diabetes 5+ years after data collection, 1 = glucose test positive for diabetes within 5 years of data collection\n",
    "\n",
    "Diabetes was diagnosed by a plasma glucose concentration level greater than 200 mg/dl at 2 hours in an oral glucose tolerance test. All patients had a negative glucose test for diabetes at initial data collection (Smith et al., 1988). In choosing parameters for our classifier, we have chosen to narrow our scope to the 5 modifiable and reversible variables in the dataset. This allows doctors to focus on modifying lifestyle factors within the patients' control.\n",
    "\n",
    "**Research Question:**\n",
    "Can our K-nearest neighbors classifier predict the onset of diabetes within a five-year time frame (`Outcome`) based on the 5 modifiable measures of health below with a high degree of accuracy, precision, and recall (>75%)?\n",
    " 1. `Glucose`: Plasma glucose concentration level at 2 hours in an oral glucose tolerance test (ie. glucose test, mg/dl)\n",
    " 2. `BloodPressure`: Diastolic blood pressure (mmHg)\n",
    " 3. `SkinThickness`: Triceps skin fold thickness (mm) (measure of body fat)\n",
    " 4. `Insulin`: 2-Hour serum insulin (µU/mL)\n",
    " 5. `BMI`: Body mass index (kg/m^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f179db34-1adb-4883-a659-af6756c06ec3",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f601df-57e8-4b09-8646-f9f2d13fa832",
   "metadata": {},
   "source": [
    "Our classifier was trained to predict diabetes development in the next 5 years (ie. pre-diabetes, `Outcome`) using K-nearest neighbors analysis. First, all non-modifiable/irreversible variables and `N/A` values were filtered out of our dataset. The filtered dataset (n = 392) was split into training (75% of the data) and testing (25% of the data) sets. The training set was used for exploratory analysis of the dataset: the mean of each variable in the non-diabetic and pre-diabetic groups were calculated, and the distributions of each variable were visualized. To select the appropriate value of K (number of neighbors) for our classifier, the training data was split into 10 subsets for cross-validation, and the cross-validation sets were used to tune the model. The accuracy estimates from K = 1 to K = 100 were visualized, and the optimal accuracy estimate was set at K = 21 for the classifier. The classifier was subsequently trained using the chosen K, with all the variables in the filtered dataset selected as parameters for classification of impending diabetes development (`Outcome`). The classifier was evaluated on the testing set, and the resulting predictions were compared to the actual outcome in the study as a confusion matrix. The proportion of true negative, false negative, true positive, and false positive predictions by our classifier was calculated from the confusion matrix data and visualized. Accuracy, precision, and recall of the classifier were all calculated from the confusion matrix to evaluate the quality of classifier predictions.\n",
    "\n",
    "Data wrangling and cleaning was performed using the `tidyverse` package. Visualization was performed using the `tidyverse`, `cowplot`, and `gridExtra` packages. The dataset was split into training/testing sets, the classifier was built/trained, K was optimized, and the confusion matrix was created using the `tidymodels` package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6862ea7-b14a-4d65-b2ee-861e6dd578d6",
   "metadata": {},
   "source": [
    "# Analysis and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cea439d-6f61-437a-a264-311b49ab75dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing and Tidying Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7faa69-9690-46ce-9a76-095c257ff177",
   "metadata": {},
   "source": [
    "Read in `diabetes.csv` from the `DSCI_100_Diabetes_Prediction` repository on GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43457b52-3728-411a-9af8-e907c8dd859f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read in data\n",
    "diabetes_dataset <- read_csv(\"https://raw.githubusercontent.com/hesoru/DSCI_100_Diabetes_Prediction/main/Dataset/diabetes.csv\")\n",
    "\n",
    "# view dataset variables and tibble dimensions\n",
    "colnames(diabetes_dataset)\n",
    "dim(diabetes_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba4ae9-244b-4d6a-a001-f3ae06650211",
   "metadata": {},
   "source": [
    "We will remove irreversible or non-modifiable variables from our classifier: `Pregnancies` (not a reversible variable), `DiabetesPedigreeFunction` (probability of diabetes based on family history), and `Age`.\n",
    "\n",
    "The dataset has no `N/A` values, however some cells have a value equal to 0. `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, and `BMI` cannot have a reading of 0 in practice, so cells with a value of 0 in these columns will be treated as `N/A` and filtered out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e41753-f344-4a6f-ac29-aaf5c2643533",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diabetes_dataset_filtered <- diabetes_dataset |>\n",
    "    select(-Pregnancies, -DiabetesPedigreeFunction, -Age) |>\n",
    "    filter(Glucose != 0, BloodPressure != 0, SkinThickness != 0, Insulin != 0, BMI != 0)\n",
    "\n",
    "# view dataset variables and tibble dimensions\n",
    "colnames(diabetes_dataset_filtered)\n",
    "dim(diabetes_dataset_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026996e1-04cb-4813-b3d9-10ead75b2cf7",
   "metadata": {},
   "source": [
    "Note that we have filtered out approximately half of the patients in our dataset, with a final sample size of n = 392."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c70fb-5f89-4670-8551-6e18bc41af5c",
   "metadata": {},
   "source": [
    "## Splitting Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becab3da-6db3-42cd-acf0-e369d5224397",
   "metadata": {},
   "source": [
    "Now that our data is tidy, we will split our data into training (75% of the data) and testing (25% of the data) sets, and convert the categorical variable `Outcome` into the factor data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae13e9-5e18-4a1a-a718-f2a2dd62fd4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(1000)\n",
    "\n",
    "diabetes_dataset_filtered_split <- initial_split(data = diabetes_dataset_filtered,\n",
    "                                                 prop = 0.75,\n",
    "                                                 strata = Outcome)\n",
    "training_filtered <- training(diabetes_dataset_filtered_split) |>\n",
    "    mutate(Outcome = as_factor(Outcome))\n",
    "testing_filtered <- testing(diabetes_dataset_filtered_split) |>\n",
    "    mutate(Outcome = as_factor(Outcome))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c48220-18aa-44e2-b86c-906635c2c325",
   "metadata": {},
   "source": [
    "## Exploration of Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f093ab-81e9-4e87-bfab-48f000536ada",
   "metadata": {},
   "source": [
    "First, we will find the mean of each variable in the groups that did (`Outcome` = 1) and did not (`Outcome` = 0) develop diabetes within 5 years of data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c635c5b-e4dc-4b3d-97df-b2319277fe12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "patient_means_by_outcome <- training_filtered |>\n",
    "    group_by(Outcome) |>\n",
    "    summarise(Patients = n(),\n",
    "              Mean_Glucose = mean(Glucose),\n",
    "              Mean_BP = mean(BloodPressure),\n",
    "              Mean_SkinThickness = mean(SkinThickness),\n",
    "              Mean_Insulin = mean(Insulin),\n",
    "              Mean_BMI = mean(BMI))\n",
    "patient_means_by_outcome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40488d1e-bd2d-4268-a8de-3bf0a95b4472",
   "metadata": {},
   "source": [
    "**Table 1. Mean health measurements in Pima Indian female patients that did (`Outcome` = 1) and did not (`Outcome` = 0) develop diabetes within 5 years of data collection.** `Glucose` = plasma glucose concentration level at 2 hours in an oral glucose tolerance test (ie. glucose test, mg/dl), `BloodPressure` = diastolic blood pressure (mmHg), `SkinThickness` = triceps skin fold thickness (mm) (measure of body fat), `Insulin` = 2-Hour serum insulin (µU/mL), `BMI` = body mass index (kg/m^2)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186521e5-21f8-4a41-bb9d-b48200b1272b",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "- 97/293 patients (33.1%) received a positive glucose test for diabetes (`Outcome` = 1) within 5 years of data collection. This implies a startling rate of diabetes development, however it is possible that some patients were already diabetic at data collection (false negatives). It is also likely that a large number of non-diabetics were filtered out when tidying our data.\n",
    "- There is a large relative difference (at least 25%) in `Mean_Glucose` and `Mean_Insulin` between pre-diabetics and non-diabetics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73f438d-9f38-411f-b7d0-848f3de2bc29",
   "metadata": {},
   "source": [
    "Next we plotted the distributions of each variable in the groups that did (pre-diabetic) and did not (non-diabetic) develop diabetes within 5 years of data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4362c-f395-4b5f-a7b4-a69482d330fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width = 10, repr.plot.height = 7)\n",
    "\n",
    "patient_distribution_glucose <- training_filtered |>\n",
    "    ggplot(aes(x = Glucose)) +\n",
    "    geom_histogram(bins = 10, binwidth = 5, aes(fill=Outcome)) +\n",
    "    labs(x = \"Glucose Plasma Concentration (mg/dl)\",\n",
    "         y = \"Number of Patients\") +\n",
    "    theme(text = element_text(size = 10)) +\n",
    "    theme(legend.position = \"none\")\n",
    "\n",
    "patient_distribution_BP <- training_filtered |>\n",
    "    ggplot(aes(x = BloodPressure)) +\n",
    "    geom_histogram(bins = 10, binwidth = 4, aes(fill=Outcome)) +\n",
    "    labs(x = \"Diastolic Blood Pressure (mmHg)\",\n",
    "         y = \"Number of Patients\") +\n",
    "    theme(text = element_text(size = 10)) +\n",
    "    theme(legend.position = \"none\")\n",
    "\n",
    "patient_distribution_SkinThickness <- training_filtered |>\n",
    "    ggplot(aes(x = SkinThickness)) +\n",
    "    geom_histogram(bins = 10, binwidth = 2, aes(fill=Outcome)) +\n",
    "    labs(x = \"Tricep Skin Thickness (mm)\",\n",
    "         y = \"Number of Patients\") +\n",
    "    theme(text = element_text(size = 10)) +\n",
    "    theme(legend.position = \"none\")\n",
    "\n",
    "patient_distribution_Insulin <- training_filtered |>\n",
    "    ggplot(aes(x = Insulin)) +\n",
    "    geom_histogram(bins = 10, binwidth = 25, aes(fill=Outcome)) +\n",
    "    labs(x = \"2-Hour Serum Insulin (µU/mL)\",\n",
    "         y = \"Number of Patients\") +\n",
    "    theme(text = element_text(size = 10)) +\n",
    "    theme(legend.position = \"none\")\n",
    "\n",
    "patient_distribution_BMI <- training_filtered |>\n",
    "    ggplot(aes(x = BMI)) +\n",
    "    geom_histogram(bins = 10, binwidth = 2, aes(fill=Outcome)) +\n",
    "    labs(x = \"Body Mass Index (kg/m^2)\",\n",
    "         y = \"Number of Patients\") +\n",
    "    theme(text = element_text(size = 10)) +\n",
    "    theme(legend.position = \"none\")\n",
    "\n",
    "# will grab legend from this plot - plot will remain unvisualized\n",
    "outcome_legend <- training_filtered |>\n",
    "    ggplot(aes(x = BMI)) +\n",
    "    geom_histogram(bins = 10, binwidth = 2, aes(fill=Outcome)) +\n",
    "    labs(x = \"Body Mass Index (kg/m^2)\",\n",
    "         y = \"Number of Patients\") +\n",
    "    scale_fill_discrete(labels=c('Non-Diabetic', 'Pre-Diabetic')) +\n",
    "    theme(text = element_text(size = 10)) \n",
    "# grab legend\n",
    "legend <- cowplot::get_legend(outcome_legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724119fd-255b-4eb8-8d92-564a377c9ff8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot all distributions on a grid\n",
    "grid.arrange(patient_distribution_glucose,\n",
    "             patient_distribution_BP,\n",
    "             patient_distribution_SkinThickness,\n",
    "             patient_distribution_Insulin,\n",
    "             patient_distribution_BMI,\n",
    "             legend,\n",
    "             ncol=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f87b3-f281-403c-8655-644fe241c41b",
   "metadata": {},
   "source": [
    "**Figure 1. Distributions of health measurements in Pima Indian female patients that did (pre-diabetic) and did not (non-diabetic) develop diabetes within 5 years of data collection.** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81465237-ee87-4df0-a75f-00f3ec84a091",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "- The distributions for glucose plasma concentration and 2-hour serum insulin appear to have different centers for non-diabetics and pre-diabetics. This is consistent with **Table 1**, which shows that the means for glucose plasma concentration and 2-hour serum insulin are significantly different between non-diabetics and pre-diabetics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a452e48b-3217-4aff-abe3-601f1eeb4dd8",
   "metadata": {},
   "source": [
    "## Selecting K for the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9f42d1-e53d-4948-a4bc-42b26c24acb9",
   "metadata": {},
   "source": [
    "First we will set up the model recipe, K-nearest neighbor classification specifications, split the training data into 10 subsets for cross-validation, and set the K-values to test. We chose to test our classifier from K = 1 to K = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1111c8c6-a0cb-465c-adfb-a70e2bdd0c1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(1000)\n",
    "\n",
    "knn_recipe <- recipe(Outcome ~ ., data = training_filtered) |>\n",
    "    step_scale(all_predictors()) |>\n",
    "    step_center(all_predictors())\n",
    "\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"classification\")\n",
    "\n",
    "vfold <- vfold_cv(training_filtered, v = 10, strata = Outcome)\n",
    "\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 100, by = 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e59b3-5475-45ed-a613-a2dbf3a3848e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we will calculate and visualize the accuracy of our model from K = 1 to K = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828de439-8a81-43a6-9449-97a1994eac2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "knn_results <- workflow() |>\n",
    "  add_recipe(knn_recipe) |>\n",
    "  add_model(knn_spec) |>\n",
    "  tune_grid(resamples = vfold, grid = k_vals) |>\n",
    "  collect_metrics() \n",
    "                 \n",
    "accuracies <- knn_results |>\n",
    "    filter(.metric ==\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2a41b3-8479-4a11-8754-b9ae42b09b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cross_val_plot <- ggplot(accuracies, aes(x = neighbors, y = mean)) +\n",
    "  geom_point() +\n",
    "  geom_line() +\n",
    "  labs(x = \"Neighbors\", y = \"Accuracy Estimate\") + \n",
    "  theme(text = element_text(size = 15))\n",
    "cross_val_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c515291-3d57-4a6a-83ab-eaf7701125bd",
   "metadata": {},
   "source": [
    "**Figure 2. Estimated accuracy of model plotted against the number of neighbors for K-nearest neighbors classification.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f6920e-8721-49bf-b3ad-cd2c416be655",
   "metadata": {},
   "source": [
    "Setting the number of neighbors to K = 21 provides the highest estimated accuracy, thus we will move forward using this K-value for the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303ca028-f11e-43a0-b11d-8abe9ccdbb02",
   "metadata": {},
   "source": [
    "## Training the Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619de862-de88-4ca7-bc98-5cb33a434456",
   "metadata": {},
   "source": [
    "Now we will combine our recipe, K-nearest neighbor classification specifications (with our newly determined K), and training data to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de56d7db-d68a-4e8a-9e5a-ac17e5cb3568",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(1000)\n",
    "\n",
    "# our knn_recipe was defined previously when tuning the classifier\n",
    "\n",
    "mnist_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 21) |> \n",
    "    set_engine(\"kknn\") |>\n",
    "    set_mode(\"classification\")\n",
    "\n",
    "mnist_fit <- workflow() |>\n",
    "    add_recipe(knn_recipe) |>\n",
    "    add_model(mnist_spec) |>\n",
    "    fit(data = training_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fa3d2e-71a9-45eb-bb48-6c293caed480",
   "metadata": {},
   "source": [
    "## Evaluating the Classifier's Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573dfabe-4bf3-41eb-aa6a-00f5f81a68d8",
   "metadata": {},
   "source": [
    "We will build a confusion matrix based off our classifier's labelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daaebde-bf58-424b-8b77-685d729605b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set.seed(1000)\n",
    "\n",
    "mnist_predictions <- predict(mnist_fit, testing_filtered) |>\n",
    "    bind_cols(testing_filtered)\n",
    "\n",
    "mnist_metrics <- mnist_predictions |>\n",
    "    metrics(truth = Outcome, estimate = .pred_class) |>\n",
    "    filter(.metric == \"accuracy\")\n",
    "\n",
    "mnist_conf_mat <- mnist_predictions |>\n",
    "    conf_mat(truth = Outcome, estimate = .pred_class)\n",
    "mnist_conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ed4ae9-2ba3-458e-a11c-897a7e62dfcc",
   "metadata": {},
   "source": [
    "**Table 2. Confusion matrix comparing classifier predictions (Prediction) against actual results (Truth).** Predictions by our classifier were assessed after classifying our testing dataset (n = 99) of adult Pima Indian female patients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2e6b6e-58ad-478f-b5a8-d8b0cc8d4765",
   "metadata": {},
   "source": [
    "The confusion matrix above can also be written in terms of the number of true positive, true negative, false positive, and false negative results by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f35d0b-f4cc-4b68-adcf-9fc1778bd7d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "conf_mat_table <- data.frame(T_or_F = c(\"True\", \"False\", \"True\", \"False\"),\n",
    "                             Neg_or_Pos = c(\"Negative (Non-Diabetic)\", \"Negative (Non-Diabetic)\",\n",
    "                                            \"Positive (Pre-Diabetic)\", \"Positive (Pre-Diabetic)\"),\n",
    "                             Count = c(61, 19, 14, 5)) |>\n",
    "                             mutate(Proportion = Count/99)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5572cd41-6dc3-4780-9eed-b9c43986b175",
   "metadata": {},
   "source": [
    "Which can be visualized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fac23e-cc15-4765-81a7-7a091649bc31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnist_plot <- ggplot(conf_mat_table, aes(x = Neg_or_Pos, y = Proportion, fill = T_or_F)) +\n",
    "       geom_bar(stat = \"identity\") +\n",
    "       labs(x = \"Negative or Positive Predictions\",\n",
    "            y = \"Proportion of Total Predictions\",\n",
    "            fill = \"True or False\") +\n",
    "       theme(text = element_text(size = 17))\n",
    "mnist_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba977628-c071-4bfe-929c-fc3a4056fd5b",
   "metadata": {},
   "source": [
    "**Figure 3. Evaluation of K-nearest neighbor classifier predictions.** The proportion of true negative, false negative, true positive, and false positive predictions by our classifier was determined after classifying our testing dataset (n = 99) of adult Pima Indian female patients. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c1cb8d-2362-4748-8ef0-bebd025672e9",
   "metadata": {},
   "source": [
    "Additionally, we can calculate accuracy, precision, and recall of our classifier using the data from our confusion matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4526426-bd19-44ee-8ee1-7c23f97ab2d2",
   "metadata": {},
   "source": [
    "## $ \\textrm{accuracy} = \\frac{\\textrm{number of correct predictions}}{\\textrm{total number of predictions}} = \\frac{\\textrm{61 + 14}}{\\textrm{61 + 19 + 5 + 14}} = 0.7576 $\n",
    "\n",
    "## $ \\textrm{precision} = \\frac{\\textrm{number of correct positive predictions}}{\\textrm{total number of positive predictions}} = \\frac{\\textrm{14}}{\\textrm{14 + 5}} = 0.7368 $\n",
    "\n",
    "## $ \\textrm{recall} = \\frac{\\textrm{number of correct positive predictions}}{\\textrm{total number of positive test set predictions}} = \\frac{\\textrm{14}}{\\textrm{14 + 19}} = 0.4242 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ae2a1-824b-47f9-810d-5a60a6abb31c",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9749ee79-4404-4b22-85d8-e8545c338ee0",
   "metadata": {},
   "source": [
    "This study has found that a k-nearest-neighbor classification algorithm trained on the 5 selected predictors: glucose plasma concentration, diastolic blood pressure, triceps skin thickness, 2-hour serum insulin and body mass index, can achieve a relatively high (>75%) accuracy on classifying pre-diabetic patients, as early as 5 years before diagnosis.\n",
    "\n",
    "This finding is expected. It was clear in the data exploration that there exists an observable difference in the selected predictors between non-diabetic and pre-diabetic patients. Although the statistical significance of these differences was not tested for, it was hypothesized that such differences are enough to facilitate a classification algorithm. \n",
    "\n",
    "The relatively high accuracy is also supported by a number of past studies which suggested an individual correlation between the selected predictors and diabetes. Edeoga et al. suggested a positive correlation between blood glucose and blood pressure, and blood pressure was successfully used to predict pre-diabetic patients among initially normoglycemic samples. Mbanya et al. also agrees with this correlation by mentioning high blood pressure as a \"major driver\" of diabetes. Skin thickness can be used to predict body fat percentage, and the accuracy of such method has been confirmed (Jayawardena et al., 2020). Body fat percentage can then be used as a predictor of diabetes. Singh et al. and Nassr et al. have suggested a high practicality of this method. Although both of the studies focused primarily on gestational diabetes, the correlation between body fat percentage and diabetes is apparent. Similarly, high levels of fasting insulin and true insulin are strongly associated with pre-diabetes(Quan et al., 2021); He et al. suggested that body mass index is a predictor of whether a pre-diabetes patient converts to diabetes.\n",
    "\n",
    "The findings of this study combine the results of past studies in a practical case. These correlations are further confirmed and the effectiveness of these predictors combined is investigated. Unlike diabetes which is incurable at the time of writing, pre-diabetic patients can be saved from converting to diabetes if the correct treatment can be given in time. This study examined the knn-classification methods for diagnosing pre-diabetes, which can potentially be used to provide valuable extra time for pre-diabetic patients to be treated and to adapt to a different lifestyle. Furthermore, this study also reveals some possible limitations in practical usage, which can be the direction of further studies: despite the overall accuracy being acceptable, the recall of this algorithm is low. Depending on the actual requirements which differ between scenarios, a low recall can lead to patients who need to be treated or warned being neglected. Unfortunately, this study does not intend to further optimize this algorithm, leaving it as a future topic.\n",
    "\n",
    "- summarize what you found\n",
    "- discuss whether this is what you expected to find?\n",
    "- discuss what impact could such findings have?\n",
    "- discuss what future questions could this lead to?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4969a7c9-d63c-4001-9280-c8cb98dc6345",
   "metadata": {},
   "source": [
    "Our primary objective is to identify pre-diabetic patients among the Pima Indian population, with the goal of initiating lifestyle modifications to hopefully prevent the onset of diabetes.\n",
    "\n",
    "The accuracy of our classifier is quite high, identifying whether or not patients are pre-diabetic 75.76% of the time. However, our classifier is less reliable with correctly identifying pre-diabetics, identifying just 42.42% of pre-diabetic patients. Though the recall of this classifier needs to be improved, it is still an improvement on the current medical system, which does not tend to identify *any* pre-diabetic patients.\n",
    "\n",
    "There are minimal consequences to the classifier labeling a false-negative result (19.19%), as pre-diabetic patients that are missed do not yet require treatment. There are also minimal consequences to the classifier labeling a false-positive result (5.051%), as any patient would benefit from the lifestyle modifications that prevent the onset of diabetes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f485c109-6b11-4e5c-b14a-d975630e4c81",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c431cc-368b-4d37-93c9-0a6513b5ecea",
   "metadata": {},
   "source": [
    "Das, R. N. (2014). Determinants of diabetes mellitus in the Pima Indian mothers and Indian Medical Students. *The Open Diabetes Journal*, 7(1), 5–13. https://doi.org/10.2174/1876524601407010005\n",
    "\n",
    "Edeoga, C., Owei, I., Siwakoti, K., Umekwe, N., Ceesay, F., Wan, J., &amp; Dagogo-Jack, S. (2017). Relationships between blood pressure and blood glucose among offspring of parents with type 2 diabetes: Prediction of incident dysglycemia in a biracial cohort. *Journal of Diabetes and Its Complications*, 31(11), 1580–1586. https://doi.org/10.1016/j.jdiacomp.2017.07.019 \n",
    "\n",
    "He, Y., Feng, Y., Shi, J., Tang, H., Chen, L., &amp; Lou, Q. (2022). Β‐cell function and body mass index are predictors of exercise response in elderly patients with Prediabetes. *Journal of Diabetes Investigation*, 13(7), 1253–1261. https://doi.org/10.1111/jdi.13777 \n",
    "\n",
    "Jayawardena, R., Waniganayake, Y. C., Abhayaratna, S. A., &amp; Ranasinghe, P. (2020). Prediction of body fat in Sri Lankan adults: Development and validation of a skinfold thickness equation. *Diabetes & Metabolic Syndrome: Clinical Research & Reviews*, 14(2), 147–150. https://doi.org/10.1016/j.dsx.2020.02.003 \n",
    "\n",
    "Krishnamoorthy, Y., Rajaa, S., Verma, M., Kakkar, R., & Kalra, S. (2022). Spatial patterns and determinants of diabetes mellitus in Indian adult population: A secondary data analysis from nationally representative surveys. *Diabetes Therapy*, 14(1), 63–75. https://doi.org/10.1007/s13300-022-01329-6\n",
    "\n",
    "Mbanya, V. N., Mbanya, J., Kufe, C., &amp; Kengne, A. P. (2016). Effects of single and multiple blood pressure measurement strategies on&nbsp;the prediction of prevalent screen‐detected diabetes mellitus: A&nbsp;population‐based survey. *The Journal of Clinical Hypertension*, 18(9), 864–870. https://doi.org/10.1111/jch.12774 \n",
    "\n",
    "Nassr, A. A., Shazly, S. A., Trinidad, M. C., El-Nashar, S. A., Marroquin, A. M., &amp; Brost, B. C. (2018). Body fat index: A novel alternative to body mass index for prediction of gestational diabetes and hypertensive disorders in pregnancy. *European Journal of Obstetrics & Gynecology and Reproductive Biology*, 228, 243–248. https://doi.org/10.1016/j.ejogrb.2018.07.001 \n",
    "\n",
    "Quan, H., Fang, T., Lin, L., Lin, L., Ou, Q., Zhang, H., Chen, K., &amp; Zhou, Z. (2021). Effects of fasting proinsulin/fasting insulin, proinsulin/insulin, vitamin D3, and waistline on diabetes prediction among the Chinese Han population. *International Journal of Diabetes in Developing Countries*, 42(2), 218–226. https://doi.org/10.1007/s13410-021-00983-z \n",
    "\n",
    "Singh, D., Mittal, P., Bachani, S., Mukherjee, B., Mittal, M. K., &amp; Suri, J. (2023). Ultrasonographic assessment of body fat index for prediction of gestational diabetes mellitus and neonatal complications. *Journal of Obstetrics and Gynaecology Canada*, 45(11), 102177. https://doi.org/10.1016/j.jogc.2023.04.026 \n",
    "\n",
    "Smith, J.W., Everhart, J.E., Dickson, W.C., Knowler, W.C., & Johannes, R.S. (1988). Using the ADAP learning algorithm to forecast the onset of diabetes mellitus. *In Proceedings of the Symposium on Computer Applications and Medical Care*, 261-265. https://www.kaggle.com/datasets/mathchi/diabetes-data-set?fbclid=IwAR1DMzdJFDxoEqLDIZNTi3j7YJXTx_7BJwCl7sbn8syQKbQCnHfMtlsKH1E"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
